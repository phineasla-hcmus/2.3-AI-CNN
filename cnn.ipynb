{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import random\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from sklearn import model_selection\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "\r\n",
    "import PIL\r\n",
    "# https://github.com/tensorflow/tensorflow/issues/46840\r\n",
    "# https://stackoverflow.com/a/68239032/12405558\r\n",
    "if PIL.__version__ == \"8.3.0\":\r\n",
    "    raise ImportError(f\"PIL 8.3.0 is incompatible with tensorflow 2.6.0\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define Constants"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "BASE_DATA_DIR = \"./data/\"\r\n",
    "TRAIN_DIR = os.path.join(BASE_DATA_DIR, \"train\")\r\n",
    "TEST_DIR = os.path.join(BASE_DATA_DIR, \"test\")\r\n",
    "\r\n",
    "IMG_WIDTH = 128\r\n",
    "IMG_HEIGHT = 128\r\n",
    "IMG_CHANNEL = 3\r\n",
    "IMG_SIZE = (IMG_WIDTH, IMG_HEIGHT)\r\n",
    "IMG_SHAPE = (IMG_WIDTH, IMG_HEIGHT, IMG_CHANNEL)\r\n",
    "# Split training into training and validation dataset\r\n",
    "VALIDATION_SIZE = 0.2\r\n",
    "\r\n",
    "BATCH_SIZE = 20\r\n",
    "\r\n",
    "EPOCHS = 10\r\n",
    "\r\n",
    "TYPE = {\"cat\": 0, \"dog\": 1}\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare Training Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_set = os.listdir(TRAIN_DIR)\r\n",
    "types = [filename.split(\".\")[0] for filename in train_set]\r\n",
    "df = pd.DataFrame({\"filename\": train_set, \"class\": types})\r\n",
    "\r\n",
    "train_df, val_df = model_selection.train_test_split(df, test_size=VALIDATION_SIZE)\r\n",
    "\r\n",
    "TOTAL_TRAIN = train_df.shape[0]\r\n",
    "TOTAL_VAL = val_df.shape[0]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Some samples"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df[\"class\"].value_counts() #.rename({v: k for k, v in TYPE.items()})\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "cat    12500\n",
       "dog    12500\n",
       "Name: class, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 201
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(f\"Training: {len(train_df)}\")\r\n",
    "train_df.reset_index(drop=True)[\"class\"].value_counts()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training: 20000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dog    10035\n",
       "cat     9965\n",
       "Name: class, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 202
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(f\"Validation: {len(val_df)}\")\r\n",
    "val_df.reset_index(drop=True)[\"class\"].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation: 5000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "cat    2535\n",
       "dog    2465\n",
       "Name: class, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 203
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras import models, layers, losses\r\n",
    "\r\n",
    "# https://www.tensorflow.org/guide/keras/functional\r\n",
    "img_input = layers.Input(shape=IMG_SHAPE)\r\n",
    "\r\n",
    "# First convolution extracts 16 filters that are 3x3\r\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\r\n",
    "x = layers.Conv2D(16, (3, 3), activation=\"relu\")(img_input)\r\n",
    "x = layers.MaxPool2D((2, 2))(x)  # Stack layer\r\n",
    "\r\n",
    "# Same as previous convolution but with 32 filters\r\n",
    "x = layers.Conv2D(32, (3, 3), activation=\"relu\")(x)\r\n",
    "x = layers.MaxPooling2D((2, 2))(x)\r\n",
    "\r\n",
    "# Same as previous convolution but with 64 filters\r\n",
    "x = layers.Conv2D(64, (3, 3), activation=\"relu\")(x)\r\n",
    "x = layers.MaxPooling2D((2, 2))(x)\r\n",
    "\r\n",
    "# Flatten feature map to a 1-dim tensor so we can add fully connected layers\r\n",
    "x = layers.Flatten()(x)\r\n",
    "\r\n",
    "# Create a fully connected layer with ReLU activation and 512 hidden units\r\n",
    "x = layers.Dense(512, activation=\"relu\")(x)\r\n",
    "\r\n",
    "# Create output layer with a single node and sigmoid activation\r\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(x)\r\n",
    "\r\n",
    "# Create model:\r\n",
    "# input = input feature map\r\n",
    "# output = input feature map + stacked convolution/maxpooling layers + fully\r\n",
    "# connected layer + sigmoid output layer\r\n",
    "model = models.Model(img_input, output)\r\n",
    "\r\n",
    "model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\r\n",
    "\r\n",
    "model.summary()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 126, 126, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 63, 63, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 61, 61, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 512)               6423040   \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 6,447,137\n",
      "Trainable params: 6,447,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
    "\r\n",
    "GEN_PARAMS = {\r\n",
    "    \"directory\": TRAIN_DIR,\r\n",
    "    \"target_size\": IMG_SIZE,\r\n",
    "    \"batch_size\": BATCH_SIZE,\r\n",
    "    \"class_mode\": \"binary\",\r\n",
    "}\r\n",
    "\r\n",
    "train_datagen = ImageDataGenerator(rescale=1.0 / 255)\r\n",
    "val_datagen = ImageDataGenerator(rescale=1.0 / 255)\r\n",
    "\r\n",
    "train_gen = train_datagen.flow_from_dataframe(train_df, **GEN_PARAMS)\r\n",
    "val_gen = val_datagen.flow_from_dataframe(val_df, **GEN_PARAMS)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "history = model.fit(\r\n",
    "    train_gen,\r\n",
    "    epochs=EPOCHS,\r\n",
    "    validation_data=val_gen,\r\n",
    "    validation_steps=TOTAL_VAL // BATCH_SIZE,\r\n",
    "    steps_per_epoch=TOTAL_TRAIN // BATCH_SIZE,\r\n",
    ")\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "__array__() takes 1 positional argument but 2 were given",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14308/3682609074.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtrain_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTOTAL_VAL\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1132\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1134\u001b[1;33m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[0;32m   1135\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1381\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_cluster_coordinator\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1382\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1383\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1138\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1139\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[0;32m    915\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_sequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enqueuer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m     super(KerasSequenceAdapter, self).__init__(\n\u001b[0m\u001b[0;32m    918\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Shuffle is handed in the _make_callable override.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[0;32m    792\u001b[0m     \u001b[1;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m     \u001b[1;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m     \u001b[0mpeek\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    795\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    926\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    927\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 928\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m   def _handle_multiprocessing(self, x, workers, use_multiprocessing,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     63\u001b[0m         index_array = self.index_array[self.batch_size * idx:\n\u001b[0;32m     64\u001b[0m                                        self.batch_size * (idx + 1)]\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    229\u001b[0m                            \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                            interpolation=self.interpolation)\n\u001b[1;32m--> 231\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m             \u001b[1;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[1;31m# but not PIL images.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\u001b[0m in \u001b[0;36mimg_to_array\u001b[1;34m(img, data_format, dtype)\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[1;31m# or (channel, height, width)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[1;31m# but original PIL image has format (width, height, channel)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'channels_first'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __array__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "6c15f6a172f14a639408d21adc440d737f2d15e0e519ed795812a3f754ed02f5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}